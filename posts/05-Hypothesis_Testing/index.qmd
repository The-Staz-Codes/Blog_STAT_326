---
title: "Mini-Project #5"
author: "Jason Stasio"
format: 
  html:
    embed-resources: true
editor: visual
---

**Advantages and Drawbacks of Using p-values**

1.  Towards the end of Section 1, the authors say, “As ‘statistical significance’ is used less, statistical thinking will be used more.” Elaborate on what you think the authors mean. Give some examples of what you think embodies “statistical thinking.”

With this quote, the author is trying to convey the importance of not relying as heavily on p-values to draw conclusions as modern scientists do. Worrying about whether a p-value deems an investigation “statistically significant” is superficial and retracts from the actual thought process and the experiment’s scientific context. It is analogous to a student hyperfixating on obtaining high grades and not necessarily caring about the content they are learning, which leads to it deteriorating faster over time. As less emphasis is placed on the superficial p-value, the otherwise neglected experimental components and statistical thinking behind the data analysis are brought to light.

In my opinion, “statistical thinking” refers to the act of designing experiments in a way that acknowledges uncertainty and provides a way to minimize the noise that ultimately comes with data collection and analysis. Examples of statistical thinking include incorporating prior information into the collection and analysis of data, such as the prior distributions in Bayesian statistics, or using prior information as a comparison for determining if a new finding provides credible evidence for a nonzero effect in an “analysis of credibility.”

2.  Section 2, third paragraph: The authors state, “A label of statistical significance adds nothing to what is already conveyed by the value of p; in fact, this dichotomization of p-values makes matters worse.” Elaborate on what you think the authors means.

What the author means is that the p-value is a distinct piece of information, “the probability of obtaining a test statistic that is as or more in favor of the alternative hypothesis than the one observed assuming the null hypothesis is true,” that is unchanged by whether or not the user decides it is worth caring about. The label of ‘statistical significance’ is merely a label; it is subjective and does not add a layer of information that was not already there. The misconception that the ability to conclude anything is baked into the p-value itself is harmful because it negates scientific reasoning and uncertainty considerations. If the p-value somehow possessed this information, Type I & II errors wouldn’t exist, nor would assumptions be associated with “false positive risks of 20-30%,” according to Colquhoun.

3.  Section 2, end of first column: The authors state, “For the integrity of scientific publishing and research dissemination, therefore, whether a p-value passes any arbitrary threshold should not be considered at all when deciding which results to present or highlight.” Do you agree or disagree? How should it be decided which results to present/highlight in scientific publishing?

I think the p-value is useful enough not to be omitted since it can indicate whether a question warrants further investigation; however, based on the misconceptions and the disproportionate weight p-values have come to hold, I agree with the statement. Something I immediately thought of when I first read this article, which is explicitly mentioned in section 3.3.2, is how some researchers will falsify their data or make tweaks just to obtain a smaller p-value that the community deems “significant.” Due to the competitive nature and over achievement being the standard in academia, researchers are willing to manipulate their data to obtain higher impact factors on their papers. Although some information would be lost if omitting the p-value became standard, this malpractice would no longer be an issue, which I feel is a worthy trade-off.

In terms of what should be presented in scientific publishing, I think it boils down to the aforementioned notions of “statistical thinking.” If a statistical test is well-designed and incorporates scientific context to maximize the information that can be derived from it, as deemed by the researcher, then it should be included.

4.  Section 3, end of page 2: The authors state, “The statistical community has not yet converged on a simple paradigm for the use of statistical inference in scientific research – and in fact it may never do so. A one-size-fits-all approach to statistical inference is an inappropriate expectation.” Do you agree or disagree? Explain.

I agree with this statement; a universal approach to statistical inference would contradict the entire article’s rhetoric because it would eliminate the need to consider the “statistical thinking” that goes into designing or interpreting an effective experiment. The way statistical inference is utilized and how it should be interpreted depends on the scientific context and experimental structure. This is highlighted in section 3.3.2, via the quote, “we believe that the thoughtful use and interpretation of p-values will never adhere to a rigid rulebook, and will instead inevitably vary from study to study.” However, there are some core elements referenced, including assessing data quality, mechanism plausibility, and real-world benefits to an investigation, that would benefit any statistical inference approach.

5.  Section 3.2: The authors note that they are envisioning “a sort of ‘statistical thoughtfulness’.” What do you think “statistical thoughtfulness” means? What are some ways to demonstrate “statistical thoughtfulness” in an analysis?

In my mind, “statistical thoughtfulness” refers to the careful inclusion and communication of every necessary detail associated with an analysis. A researcher has exhibited “statistical thoughtfulness” if there is no room for misinterpretation in the results they present. As the article argues, solely depending on the p-value to determine if a statistical test is worth caring about is a gross misinterpretation, and it would be better practice to include multiple assessments in addition to (or in place of) the p-value threshold assessment. For instance, the article mentions the belief of a statistician that a confidence index should be included with every approach to statistical analysis. The article also mentions that thoughtful research: “looks ahead to prospective outcomes based on theory and previous research, carefully considers meaningful effect size, considers multiple approaches, and uses a toolbox of statistical techniques.” In other words, to practice “statistical thoughtfulness” is to utilize statistics to address a scientific question from multiple angles.

6.  Section 3.2.4: A few of the authors of papers in this special issue argue that some of the terminology used in statistics, such as “significance” and “confidence,” can be misleading, and they propose the use of “compatibility” instead. What do you think they believe the problem is? Do you agree or disagree (that there is a problem and that changing the name will help)?

While the terms “significance” and “confidence” can be misleading (we discussed how confidence intervals are unintuitive and the more natural interpretation aligns with credible intervals, the Bayesian analogue, and “significance” seems to assign a disproportionate amount of weight to the p-value), I don’t think their use is a major issue among the statistics community. Given the rigorous training/schooling associated with becoming a statistician, statisticians are unlikely to hold the misconceptions that could arise from the terminology. As with any field, certain customs and terminology have been widely accepted and used for a long time, which makes them resistant to change (e.g., defining the counterclockwise direction to be positive in physics and linear algebra, etc.). It is the responsibility of the person using/learning the terminology to dissect what it means and apply it properly.

In my opinion, the perceived problem is that, given how other fields such as biology and economics rely on statistics, someone with less rigorous statistical training may fail to understand the uncertainty associated with statistical analyses, almost as though it is masked by the terminology. While changing the name to “compatibility” could rectify this concern, the professionals in these fields are highly adaptable. I believe potential misconceptions could easily be addressed by drawing more attention to them when the material is learned/used.

7.  Find a quote or point that really strikes you (i.e., made you think). What is the quote (and tell me where to find it), and why does it stand out to you?

A quote that stood out to me comes from the referenced statistician Goodman and appears in the second paragraph at the beginning of section 5, “It’s the same reason we can use money. When everyone believes in something’s value, we can use it for real things; money for food, and p-values for knowledge claims, publication, funding, and promotion. It doesn’t matter if the p-value doesn’t mean what people think it means; it becomes valuable because of what it buys.” I find this analogy to be particularly effective and thought-provoking because it forces the reader to consider the psychology behind what gives things “value.” Money itself is not inherently valuable; it is a green piece of paper, but the ability to use this paper to obtain desired items gives it value. Similarly, a p-value is not an indisputable indicator of whether results are worth caring about; however, it is treated as such by scientists and therefore assumes this problematic role.
