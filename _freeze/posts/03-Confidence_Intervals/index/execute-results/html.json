{
  "hash": "2b8bae6e8eae0bec44e3f83d2ee1caa9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Mini-Project #3\"\nauthor: \"Jason Stasio\"\nformat: \n  html:\n    embed-resources: true\neditor: visual\nimage: no\n---\n\n\n\n**Simulation to Investigate Confidence Intervals**\n\n## Set up\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clear the environment\nrm(list = ls())\n\n# Load in packages \nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n:::\n\n\n\n## Settings for p close to 0.5 (p = 0.56)\n\n#### For large sample size (n = 500)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run simulation\nn <- 500   # sample size\np <- 0.56  # population proportion\n\n# Define function to generate sample proportions \ngenerate_samp_prop <- function(n, p) {\n  \n  x <- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat <- x / n\n  \n  # Create 90% confidence interval \n  lb <- phat - 1.645 * sqrt(phat * (1-phat) / n)\n  ub <- phat + 1.645 * sqrt(phat * (1-phat) / n)\n  \n  prop_df <- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\n# How many CI's do we want to generate\nn_sim <- 5000\n\nprop_ci_df <- map(1:n_sim, \n    \\(i) generate_samp_prop(n=500, p=0.56)) |>\n  bind_rows()\n\n# Calculate average interval width and coverage rate\nprop_ci_df <- prop_ci_df |> mutate(ci_width = ub - lb, \n                                   ci_cover_ind = if_else(p > lb & p < ub,\n                                                              true = 1,\n                                                              false = 0))\nprop_ci_df |> summarise(avg_width = mean(ci_width),\n                                      coverage_rate = mean(ci_cover_ind))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      <dbl>         <dbl>\n1    0.0730         0.908\n```\n\n\n:::\n:::\n\n\n\n#### For medium sample size (n = 50)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run simulation\nn <- 50   # sample size\np <- 0.56  # population proportion\n\n# Define function to generate sample proportions \ngenerate_samp_prop <- function(n, p) {\n  \n  x <- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat <- x / n\n  \n  # Create 90% confidence interval \n  lb <- phat - 1.645 * sqrt(phat * (1-phat) / n)\n  ub <- phat + 1.645 * sqrt(phat * (1-phat) / n)\n  \n  prop_df <- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\n# How many CI's do we want to generate\nn_sim <- 5000\n\nprop_ci_df <- map(1:n_sim, \n    \\(i) generate_samp_prop(n=50, p=0.56)) |>\n  bind_rows()\n\n# Calculate average interval width and coverage rate\nprop_ci_df <- prop_ci_df |> mutate(ci_width = ub - lb, \n                                   ci_cover_ind = if_else(p > lb & p < ub,\n                                                              true = 1,\n                                                              false = 0))\nprop_ci_df |> summarise(avg_width = mean(ci_width),\n                                      coverage_rate = mean(ci_cover_ind))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      <dbl>         <dbl>\n1     0.229         0.886\n```\n\n\n:::\n:::\n\n\n\n#### For small sample size (n = 22)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run simulation\nn <- 22   # sample size\np <- 0.56  # population proportion\n\n# Define function to generate sample proportions \ngenerate_samp_prop <- function(n, p) {\n  \n  x <- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat <- x / n\n  \n  # Create 90% confidence interval \n  lb <- phat - 1.645 * sqrt(phat * (1-phat) / n)\n  ub <- phat + 1.645 * sqrt(phat * (1-phat) / n)\n  \n  prop_df <- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\n# How many CI's do we want to generate\nn_sim <- 5000\n\nprop_ci_df <- map(1:n_sim, \n    \\(i) generate_samp_prop(n=22, p=0.56)) |>\n  bind_rows()\n\n# Calculate average interval width and coverage rate\nprop_ci_df <- prop_ci_df |> mutate(ci_width = ub - lb, \n                                   ci_cover_ind = if_else(p > lb & p < ub,\n                                                              true = 1,\n                                                              false = 0))\nprop_ci_df |> summarise(avg_width = mean(ci_width),\n                                      coverage_rate = mean(ci_cover_ind))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      <dbl>         <dbl>\n1     0.340         0.866\n```\n\n\n:::\n:::\n\n\n\n## Settings for p far from 0.5 (p = 0.20)\n\n#### For large sample size (n = 500)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run simulation\nn <- 500   # sample size\np <- 0.2  # population proportion\n\n# Define function to generate sample proportions \ngenerate_samp_prop <- function(n, p) {\n  \n  x <- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat <- x / n\n  \n  # Create 90% confidence interval \n  lb <- phat - 1.645 * sqrt(phat * (1-phat) / n)\n  ub <- phat + 1.645 * sqrt(phat * (1-phat) / n)\n  \n  prop_df <- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\n# How many CI's do we want to generate\nn_sim <- 5000\n\nprop_ci_df <- map(1:n_sim, \n    \\(i) generate_samp_prop(n=500, p=0.2)) |>\n  bind_rows()\n\n# Calculate average interval width and coverage rate\nprop_ci_df <- prop_ci_df |> mutate(ci_width = ub - lb, \n                                   ci_cover_ind = if_else(p > lb & p < ub,\n                                                              true = 1,\n                                                              false = 0))\nprop_ci_df |> summarise(avg_width = mean(ci_width),\n                                      coverage_rate = mean(ci_cover_ind))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      <dbl>         <dbl>\n1    0.0587         0.890\n```\n\n\n:::\n:::\n\n\n\n#### For medium sample size (n = 50)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run simulation\nn <- 50   # sample size\np <- 0.2  # population proportion\n\n# Define function to generate sample proportions \ngenerate_samp_prop <- function(n, p) {\n  \n  x <- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat <- x / n\n  \n  # Create 90% confidence interval \n  lb <- phat - 1.645 * sqrt(phat * (1-phat) / n)\n  ub <- phat + 1.645 * sqrt(phat * (1-phat) / n)\n  \n  prop_df <- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\n# How many CI's do we want to generate\nn_sim <- 5000\n\nprop_ci_df <- map(1:n_sim, \n    \\(i) generate_samp_prop(n=50, p=0.2)) |>\n  bind_rows()\n\n# Calculate average interval width and coverage rate\nprop_ci_df <- prop_ci_df |> mutate(ci_width = ub - lb, \n                                   ci_cover_ind = if_else(p > lb & p < ub,\n                                                              true = 1,\n                                                              false = 0))\nprop_ci_df |> summarise(avg_width = mean(ci_width),\n                                      coverage_rate = mean(ci_cover_ind))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      <dbl>         <dbl>\n1     0.183         0.868\n```\n\n\n:::\n:::\n\n\n\n#### For small sample size (n = 22)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run simulation\nn <- 22  # sample size\np <- 0.2  # population proportion\n\n# Define function to generate sample proportions \ngenerate_samp_prop <- function(n, p) {\n  \n  x <- rbinom(1, n, p) # randomly generate number of successes for the sample\n  \n  ## number of successes divided by sample size\n  phat <- x / n\n  \n  # Create 90% confidence interval \n  lb <- phat - 1.645 * sqrt(phat * (1-phat) / n)\n  ub <- phat + 1.645 * sqrt(phat * (1-phat) / n)\n  \n  prop_df <- tibble(phat, lb, ub)\n  return(prop_df)\n}\n\n# How many CI's do we want to generate\nn_sim <- 5000\n\nprop_ci_df <- map(1:n_sim, \n    \\(i) generate_samp_prop(n=22, p=0.2)) |>\n  bind_rows()\n\n# Calculate average interval width and coverage rate\nprop_ci_df <- prop_ci_df |> mutate(ci_width = ub - lb, \n                                   ci_cover_ind = if_else(p > lb & p < ub,\n                                                              true = 1,\n                                                              false = 0))\nprop_ci_df |> summarise(avg_width = mean(ci_width),\n                                      coverage_rate = mean(ci_cover_ind))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      <dbl>         <dbl>\n1     0.269         0.821\n```\n\n\n:::\n:::\n\n\n\n## Check Assumptions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Setting 1: p = 0.56, n = 500\n500 * 0.56\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 280\n```\n\n\n:::\n\n```{.r .cell-code}\n500 * (1 - 0.56)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 220\n```\n\n\n:::\n\n```{.r .cell-code}\n# Result: 280 > 10 and 220 > 10, so large sample assumption holds\n\n# Setting 2: p = 0.56, n = 50\n50 * 0.56\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 28\n```\n\n\n:::\n\n```{.r .cell-code}\n50 * (1 - 0.56)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 22\n```\n\n\n:::\n\n```{.r .cell-code}\n# Result: 28 > 10 and 22 > 10, so large sample assumption holds\n\n# Setting 3: p = 0.56, n = 22\n22 * 0.56\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12.32\n```\n\n\n:::\n\n```{.r .cell-code}\n22 * (1 - 0.56)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.68\n```\n\n\n:::\n\n```{.r .cell-code}\n# Result: 12.32 > 10, but 9.68 < 10, so large sample assumption is violated \n\n# Setting 4: p = 0.20, n = 500\n500 * 0.20\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 100\n```\n\n\n:::\n\n```{.r .cell-code}\n500 * (1 - 0.20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 400\n```\n\n\n:::\n\n```{.r .cell-code}\n# Result: 100 > 10 and 400 > 10, so large sample assumption holds \n\n# Setting 5: p = 0.20, n = 50\n50 * 0.20\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10\n```\n\n\n:::\n\n```{.r .cell-code}\n50 * (1 - 0.20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 40\n```\n\n\n:::\n\n```{.r .cell-code}\n# Result: 10 = 10 and 40 > 10, so the large sample assumption is right on the line of being violated\n\n# Setting 6: p = 0.20, n = 22\n22 * 0.20\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.4\n```\n\n\n:::\n\n```{.r .cell-code}\n22 * (1 - 0.20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 17.6\n```\n\n\n:::\n\n```{.r .cell-code}\n# Result: 17.6 > 10, but 4.4 < 10, so large sample assumption is violated \n```\n:::\n\n\n\n## Table of Results\n\n|            |               | $n = 22$ | $n = 50$ | $n = 500$ |\n|:----------:|:-------------:|:--------:|:--------:|:---------:|\n| $p = 0.56$ | Coverage Rate |  0.862   |  0.887   |   0.905   |\n| $p = 0.20$ | Coverage Rate |  0.839   |  0.869   |   0.897   |\n|            |               |          |          |           |\n| $p = 0.56$ | Average Width |  0.340   |  0.229   |  0.0730   |\n| $p = 0.20$ | Average Width |  0.270   |  0.183   |  0.0588   |\n\n: Table of Results {.striped .hover}\n\n## Summary\n\nThe purpose of this project was to examine confidence intervals and coverage rates across 6 different settings to assess the importance of the \"large sample size\" assumption. The first three settings used a proportion value close to 0.5, p = 0.56, and varied the sample sizes, n = 500 (large), n = 50 (medium), and n = 22 (small). The trend observed for confidence intervals was that the average width decreased as sample size increased, 0.340 (n = 22) \\> 0.229 (n = 50) \\> 0.0730 (n = 500). Mathematically, this makes sense as the formula for confidence intervals involves subtracting or adding a quantity that is divided by the square root of the sample size, which shrinks as n increases. The trend observed for coverage rates is that the larger the sample size, the closer they were to the expected 0.90, since we were calculating a 90% confidence interval, \\|0.90 - 0.862\\| = 0.038 (n = 22) \\> \\|0.90 - 0.887\\| = 0.013 (n = 50) \\> \\|0.90 - 0.905\\| = 0.005 (n = 500).\n\nThe latter three settings used a proportion value far from 0.5, p = 0.2, and varied the sample sizes by the same amounts as the first three settings, n = 500, n = 50, and n = 22. For confidence intervals, a similar trend was observed where average width decreased as sample size increased, 0.270 (n = 22) \\> 0.183 (n = 50) \\> 0.0588 (n = 500). A similar trend was also observed for coverage rates as larger sample sizes were closer to the expected coverage rate of 0.90, \\|0.90 - 0.839\\| = 0.061 (n = 22) \\> \\|0.90 - 0.869\\| = 0.031 (n = 50) \\> \\|0.90 - 0.897\\| = 0.003 (n = 500).\n\nBetween the different proportion values, p = 0.20, on average, always produced shorter confidence interval widths than p = 0.56 across the different population sizes. This suggests that the maximum average width occurs when the proportion is in the middle (p = 0.5) and decreases as the proportion we are examining moves to the left (closer to p = 0) or right (closer to p = 1). In general, p = 0.56 seems to produce higher coverage rates that are closer to the expected 0.9, except in the n = 500 case, where p = 0.2 was closer (0.005 vs 0.003), but not by much in each case. Sample size had a far more noticeable impact on coverage rates, with the n = 22 case producing values far from the expected 0.9 (distances of 0.038 and 0.061) and the n = 500 case producing values close to the expected 0.9 (distances of 0.003 and 0.005). Note that the \"large sample size\" assumption was violated for n = 20 but held for n = 500. For the case of n = 50, the assumption was on the line of being violated for p = 0.2 (producing a distance of 0.031) and held for p = 0.56 (producing a distance of 0.013). These findings suggest that measuring confidence intervals and coverage rates is only reliable or meaningful if the \"large sample size\" assumption holds. We want our confidence intervals to be short and our coverage rates to be close to 0.9, which we observe for n = 500, somewhat for n = 50, but not for n = 22.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}